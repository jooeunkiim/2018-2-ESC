---
title: "Week4"
author: "김주은"
date: "2018년 10월 7일"
output: html_document
---
일단 디렉토리 설정 후 파일을 읽어들인 다음 패키지를 깐다.
```{r}
setwd("C:/Users/Jooeun Kim/Desktop/ESC/Week4 Assignment")
read.csv(file='nba.csv') -> nba
str(nba)
if(!require(glmnet)){install.packages('glmnet')}
library(glmnet)
```
먼저 저번주에 했던 variable selection 과정을 통해 불필요한 변수들을 제거해준다.  
rank 변수들은 단순히 이미 존재하는 변수들의 순위를 나타내는 것이기 때문에 불필요하고, WIN과 LOSE, GP, W_PCT 변수도 서로의 조합으로 만들 수 있기 때문에 WIN PERCENT 변수만을 남기고 없애준다.
```{r}
nba[-c(27:51)] -> nba
nba[-c(2:4)] -> nba
```

input과 response variable을 지정해준다.
```{r}
which(names(nba) == 'SALARY_MILLIONS') -> index
as.matrix(nba[index]) -> y
as.matrix(nba[-index]) -> x
```
1. ridge regression을 수행하는 함수는 `glmnet(alpha=0)`
```{r}
glmnet(x=x, y=y, alpha=0) -> ridge.fit
ridge.fit
plot(ridge.fit)
plot(ridge.fit, xvar="lambda", label=TRUE)
```
  
  $\lambda$가 작아질수록 설명된 deviation의 퍼센티지가 높아지는 사실을 확인할 수 있다. 또한 $\lambda$가 클수록, 즉 penalty가 강하게 부과될 수록, 회귀계수의 추정치들이 0으로 다가간다.    
2. obtaining best $\lambda$  
```{r}
ridge.fit.cv <- cv.glmnet(x=x, y=y, alpha=0, type.measure="mse", nfolds=20)
ridge.fit.cv$lambda.min
```
20개의 폴드를 통해 얻을 수 있는 최적의 값을 구하고, 이를 통한 계수들을 구해본다.
```{r}
coef(ridge.fit.cv, s="lambda.min")
predict(ridge.fit.cv, newx=x, s="lambda.min")
plot(ridge.fit.cv)
```
  람다를 통해 구한 계수들의 fitted value를 구해보고, 이 람다에서 에러가 최소화됨을 확인할 있다.  
  
3. lasso regression을 수행하는 함수는 `glmnet(alpha=1)`
```{r}
glmnet(x=x, y=y, alpha=1) -> lasso.fit
lasso.fit
plot(lasso.fit)
plot(lasso.fit, xvar="lambda", label=TRUE)
```
  
  $\lambda$가 커지고 페널티가 강하게 부과될수록 따라 0으로 수렴하는 회귀계수들이 많아 Sparse해진다.
  
4. obtaining best $\lambda$  
lasso regression 역시 k-folds cross validation을 통해 test error을 최소화하는 람다를 구하고, 이를 통한 회귀계수 추정치와 fitted value, 그리고 최소화된 error을 확인할 수 있다.
```{r}
lasso.fit.cv <- cv.glmnet(x=x, y=y, alpha=1, type.measure="mse", nfolds=20)
lasso.fit.cv$lambda.min
coef(lasso.fit.cv, s="lambda.min")
predict(lasso.fit.cv, newx=x, s="lambda.min")
plot(lasso.fit.cv)
```
  
5. 성능 비교
```{r}
plot(log(ridge.fit.cv$lambda), ridge.fit.cv$cvm, pch=19, col="red", xlab="log(Lambda)", ylab=ridge.fit.cv$name)
points(log(lasso.fit.cv$lambda), lasso.fit.cv$cvm, pch=19,col="blue")
legend("topleft",legend=c("Ridge", "Lasso"), pch=19, col=c("red", "blue"))
```